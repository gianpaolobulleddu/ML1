{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d4b226b",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning through Julia\n",
    "\n",
    "In this subject, the practice is focused on the study of different Machine Learning models. The aim is to understand how they work and how to use them to solve real-world problems. The main points to cover will be: \n",
    "\n",
    "* Artificial Neuron Networks\n",
    "* Support Vector Machines \n",
    "* Decision Trees \n",
    "* k-Nearest Neighbours (KNN)\n",
    "* Ensemble Approaches\n",
    "\n",
    "To cover all these concepts, the programming language Julia will be used. The latter, being a language mainly for development and research, will allow us to indeep the whole process of using the aforementioned systems.  In a first approach, in order to gain familiarity with the language, an ANN training will be implemented. This will also serve as an introduction to ANNs, their correct definition and training.\n",
    "\n",
    "From a general view, the practicum will cover two tasks in parallel: \n",
    "\n",
    "* In the first weeks, through tutorials like this one, coding tasks of different parts of a Machine Learning system, such as a cross validation or the metrics to be used, will be performed. Given that during these first weeks the degree of development of the practical application will be very restricted, the practices will take a well-known problem, the iris flower classification problem, as a benchmark.  However, as the code is developed in these tutorials, it is expected to be integrated into the final system. In other words, in each practice, a part of the final system will be developed.\n",
    "\n",
    "\n",
    "* In parallel, each working team will have to carry out the tasks inherent to the problem they have set out to solve.  These tasks include data acquisition, data analysis, loading the database in Julia, etc.  As the tutorials progress, these advances must be integrated and applied to solve the problem, which will be reflected in the different memory deliverables. \n",
    "\n",
    "Therefore, during the first weeks there will be a double objective: on the one hand to learn how to implement the different parts of a machine learning system, and on the other hand to start working on the proposed practical application. For this purpose, the code that is being developed will be integrated incrementally. Once the tutorials have been completed, the work will focus solely on solving the proposed problem, using different approaches.\n",
    "\n",
    "As previously mentioned, the iris flower problem will be used as an illustrative problem for the development of the code in the tutorials.  This is possibly the best known database in the field of pattern recognition.  This database was published by Fisher in 1936 as an example of linear discriminant analysis, and since then it has been used on many occasions as a benchmark for new systems or simply for learning. This database contains 150 instances belonging to 3 classes: Iris Setosa, Iris Versicolor and Iris Virginica. Each of these classes has 50 instances belonging only to that class giving a simple classification problem.  It should be noted that one of these classes is linearly separable from the other two, while they are not linearly separable from each other.  Each instance consists of 4 attributes, which are lengths and widths of sepals and petals, measured in centimetres.\n",
    "\n",
    "The database to be used in these practices can be downloaded from the UCI website, at the following address: [http://archive.ics.uci.edu/dataset/53/iris](http://archive.ics.uci.edu/dataset/53/iris) ,specifically, the file to be downloaded is called \"iris.data\". \n",
    "\n",
    "This first tutorial aims to install and become familiar with Julia. To do so, a code will be developed to load this database in Julia and perform a basic preprocessing. This basic preprocessing has to do with the use of numerical inputs and/or outputs instead of categorical ones, and the normalisation of the data. \n",
    "\n",
    "With respect to the treatment of categorical values, this is a very common step, since many models such as NRs do not accept categorical inputs and outputs, but only work with numerical values. In contrast, many of the databases have categorical inputs and/or outputs rather than numerical ones. Therefore, in order for models that only accept numerical inputs and outputs to process them, it is necessary to convert these categorical values into numerical values: \n",
    "\n",
    "\n",
    "* If there are only two categories, e.g. true/false, green/blue, wood/metal or expensive/cheap, that attribute is transformed into a single attribute, which takes the value false or 0 for one category and true or 1 for the other. \n",
    "\n",
    "* If there are more than two categories, for example red/green/blue, wood/metal/plastic or car/boat/plane/train, it is transformed into as many attributes as there are possibilities, one for each category, with value 1 for those instances that belong to it and 0 for those that do not.  For example, in the red/green/blue case, the patterns with value \"red\" will become (1, 0, 0), the \"green\" ones (0, 1, 0) and the \"blue\" ones (0, 0, 1). \n",
    "\n",
    "* A third possibility, when there are more than two categories, is to convert them into a single real number.  For example, A/B/C/D could become 0/0.33/0.66/1. However, this case is only interesting when in the real world there is an order A < B < C < D, and is therefore not applicable in the case of iris flowers.\n",
    "\n",
    "In the case of the iris flower database, this situation occurs only in the desired output, which needs to be encoded. \n",
    "\n",
    "With respect to data normalisation, training a model will be much faster if the inputs provided are on the same scale, i.e. if the model is spared from having to learn the relationship between the scales on which each attribute moves.  This process of converting the inputs so that they are all in the same range is called **normalisation** or **standarization**, and is one of the most common and important types of pre-processing.  This type of preprocessing allows a simpler model to solve more complex problems than without it, since it does not need to use part of it to learn the relationship between the scales of the input attributes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93326bc9",
   "metadata": {},
   "source": [
    "### Question 1.1\n",
    "> ❓ Would this pre-processing be necessary when the inputs are the intensity values of each pixel in a black and white image? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb95269",
   "metadata": {},
   "source": [
    "`Answer here`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53977ca2",
   "metadata": {},
   "source": [
    "There are many other types of pre-processing, such as noise clean-up, PCA analysis, etc.  Some of them will be covered in depth in other subjects.  Regarding normalisation, more is explained in theory classes, but in practice one of the following two types should be enough.  of these two types is used in practice:\n",
    "\n",
    "1. Normalisation between maximum and minimum. For each attribute, it takes the lowest ($min$) and highest ($max$) values, and changes all $v$ values to pass them to the new interval $[newmin, newmax]$ as follows:<br/><br/> $$v' = \\frac{v-min}{max-min}\\times(newmax-newmin) + newmin$$ <br/>Generally, one usually moves to an interval between $[0, 1]$, which simplifies the equation to:<br/><br/> $$v' = \\frac{v-min}{max-min}$$ <br/> This type of normalisation is appropriate when you are certain that the data is bounded (both top and bottom), i.e. it is within an interval.  What you are doing is changing the interval of the data to the interval $[0, 1]$ and matching each data to its new value within the new interval.  However, if you suspect that one of these data might fall outside the interval and take an excessively high or low value, this transformation can be very harmful.  In this case, this outlier would be assigned a new value of 1 if it is excessively high, and the rest of the values would oscillate close to 0 with little difference between them. On the other hand,  the value would be 0 if it is excessively low, while the rest of the values would be close to 1 with little difference between them. If it is suspected that there may be cases like this, another kind of normalization should be chosen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8049d14f",
   "metadata": {},
   "source": [
    "### Question 1.2\n",
    "> ❓ In the particular case that $min=max$, a different preprocessing can be performed on this attribute, what would it consist of?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff700bcc",
   "metadata": {},
   "source": [
    "`Answer here`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ace11b",
   "metadata": {},
   "source": [
    "2. Normalisation to the mean 0. This kind of normalisation is more robust to outliers.  For each attribute, the mean and standard deviation of all the values it takes are taken, and a simple transformation is made:<br/><br/>$$v'=\\frac{x-\\mu}{\\sigma}$$<br/> Thus, each attribute will have a mean ($\\mu$) of 0 and a standard deviation ($\\sigma$) of 1. Some values will fall outside this range, but this is not a problem for ANNs, which simply accept real values as inputs.\n",
    "\n",
    "It is important to bear in mind that, no matter which normalisation method is applied, it must be carried out independently for each attribute. That is to say, if you have a database with $N$ patterns and $L$ attributes, you would have to perform $L$ different normalisations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceb769c",
   "metadata": {},
   "source": [
    "### Question 1.3\n",
    "> ❓ Taking into account that Machine Learning models in general assume that patterns are distributed in rows, but that for ANNs they are arranged in columns, in which cases should each row be normalised separately and in which cases should each column be normalised separately?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ef1513",
   "metadata": {},
   "source": [
    "`Answer here`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba03f9c6",
   "metadata": {},
   "source": [
    "Generally speaking, knowledge about the nature of each attribute is often helpful in achieving models that deliver better results.  The more information about the data that is \"fed\" into the model, the better the model will perform. A good example of introducing information about the data is data normalisation.  This could be taken to the extreme and a different form of normalisation could be chosen, which is thought to be most appropriate, for each of the attributes.  This may lead to the decision, for example, to normalise an attribute \"temperature\" between maximum and minimum, while the attribute \"distance\" is normalised to mean 0. In most cases, however, one of these two normalisations is usually chosen and applied to all input attributes of the ANN. \n",
    "\n",
    "It is also important to note that this process also occurs at the outputs of the ANN. That is, if the outputs are in different intervals, the ANN has to learn this as well, so the ANN can be \"helped\" by normalising the output data.  This is a process that is done in regression problems, but not in classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1d434c",
   "metadata": {},
   "source": [
    "### Question 1.4\n",
    "> ❓ Why is it not performed in classification problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f818b9a",
   "metadata": {},
   "source": [
    "`Answer here`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083d689b",
   "metadata": {},
   "source": [
    "### Important:  \n",
    "In this way, the inputs (and desired outputs) that are applied to a model are no longer the original data, but the transformed ones.  Thus, once trained, a model is not ready to be passed the original data, but if data is to be applied, it will have to be transformed in the same way. For this very reason, no matter which way of normalisation is applied, it is necessary to save the  parameters used in the normalisation for each attribute (maximum and minimum or mean and standard deviation).  Similarly, if the desired output has been normalised (regression problems), the model will have learned to produce a normalised output, so it will have to be denormalised, which again means that the normalisation parameters of the desired outputs will have to be saved.  In summary, to apply new data to a model, the process will follow the next steps: \n",
    "\n",
    "1. Normalise the data according to the parameters that were used in the training set. \n",
    "2. Apply the normalized data to the model\n",
    "3. (Only for regression problems) Denormalise the outputs of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3e87a3",
   "metadata": {},
   "source": [
    "In this first assignment, the resolution of the chosen classification problem will be studied by means of different Machine Learning techniques.  To do so, during several weeks, exercises will be presented, which will allow the development of the code that will later have to be integrated in a script that will incrementally grow during the following weeks.\n",
    "\n",
    "In this the first week, you are asked to: \n",
    "\n",
    "1. Have a first contact with Julia, install the necessary packages and learn the most basic concepts of Julia.\n",
    "\n",
    "2. Download the iris flower database from the indicated address and load the database in Julia. \n",
    "    * Create a matrix with the inputs and another one with the desired outputs, each one with the most appropriate type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3095514f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\gianp\\.julia\\environments\\v1.11\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\gianp\\.julia\\environments\\v1.11\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\gianp\\.julia\\environments\\v1.11\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\gianp\\.julia\\environments\\v1.11\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\gianp\\.julia\\environments\\v1.11\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\gianp\\.julia\\environments\\v1.11\\Manifest.toml`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Columns: [\"5.1\", \"3.5\", \"1.4\", \"0.2\", \"Iris-setosa\"]\n",
      "Dataset Shape: (149, 5)\n",
      "Dataset Columns: [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\", \"Species\"]\n",
      "Dataset Columns: String15[\"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"]\n",
      "target firsts: [1, 1, 1, 1, 1]\n",
      "train firsts: \u001b[1m5×4 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m SepalLength \u001b[0m\u001b[1m SepalWidth \u001b[0m\u001b[1m PetalLength \u001b[0m\u001b[1m PetalWidth \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Float64     \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64    \u001b[0m\n",
      "─────┼──────────────────────────────────────────────────\n",
      "   1 │         4.9         3.0          1.4         0.2\n",
      "   2 │         4.7         3.2          1.3         0.2\n",
      "   3 │         4.6         3.1          1.5         0.2\n",
      "   4 │         5.0         3.6          1.4         0.2\n",
      "   5 │         5.4         3.9          1.7         0.4\n"
     ]
    }
   ],
   "source": [
    "# Type the code to load the data \n",
    "# and to convert to the appropiate type in each case\n",
    "#=\n",
    "using Pkg\n",
    "# Pkg.add(\"RDatasets\")\n",
    "using XLSX:readdata\n",
    "using RDatasets\n",
    "# Load the Iris dataset\n",
    "iris = dataset(raw\"E:\\usc\\master\\courses\\ML1\\MIA_ML1-main\\data\", \"iris.data\")\n",
    "=#\n",
    "#TODO\n",
    "# Type the code to load the data \n",
    "# and to convert to the appropiate type in each case\n",
    "\n",
    "\n",
    "# Imports first\n",
    "using Pkg\n",
    "\n",
    "# Only run once to install packages\n",
    "#=\n",
    "Pkg.add(\"CSV\") \n",
    "Pkg.add(\"DataFrames\") \n",
    "Pkg.add(\"CategoricalArrays\")\n",
    "# Import the packages\n",
    "using CSV\n",
    "using DataFrames\n",
    "using CategoricalArrays\n",
    "=#\n",
    "\n",
    "# ==================================================\n",
    "#1. Load dataset into a DataFrame\n",
    "# ==================================================\n",
    "iris = CSV.read(\"E:/usc/master/courses/ML1/MIA_ML1-main/data/iris.data\",  DataFrame, header=true)\n",
    "\n",
    "\n",
    "# Show first 5 rows\n",
    "first(iris, 5)\n",
    "\n",
    "println(\"Dataset Columns: \", names(iris))   # prints (rows, cols)\n",
    "\n",
    "# print dataframe shape\n",
    "println(\"Dataset Shape: \", size(iris))   # prints (rows, cols)\n",
    "\n",
    "# rename Columns\n",
    "rename!(iris, [:SepalLength, :SepalWidth, :PetalLength, :PetalWidth, :Species])\n",
    "\n",
    "# print renamed columns\n",
    "println(\"Dataset Columns: \", names(iris))   # prints (rows, cols)\n",
    "\n",
    "# ==================================================\n",
    "#for later usage\n",
    "# ==================================================\n",
    "train = select(iris, Not(:\"Species\"))   # features\n",
    "target = select(iris,\"Species\")\n",
    "\n",
    "# print Species unique values\n",
    "println(\"Dataset Columns: \", unique(iris.Species) )   # prints (rows, cols)\n",
    "unique(iris.Species)          # shows distinct labels\n",
    "\n",
    "# ==================================================\n",
    "# Encode Species\n",
    "# ==================================================\n",
    "using CategoricalArrays\n",
    "\n",
    "# Convert to categorical\n",
    "iris.Species = categorical(iris.Species)\n",
    "\n",
    "# Encode as numeric (1, 2, 3)\n",
    "target = levelcode.(iris.Species)\n",
    "\n",
    "\n",
    "# some print\n",
    "println(\"target firsts: \", first(target, 5) )   # prints (rows, cols)\n",
    "println(\"train firsts: \", first(train, 5) )   # prints (rows, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a2a4b4",
   "metadata": {},
   "source": [
    "> **Question**: What are the dimensions of the arrays that we expect? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3367a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (149, 4)\n",
      "target Shape: (149,)\n"
     ]
    }
   ],
   "source": [
    "# Print both inputs and targets\n",
    "# Tip: you can do this with a defensive programming\n",
    "\n",
    "#TODO\n",
    "println(\"Train Shape: \", size(train))   # prints (rows, cols)\n",
    "println(\"target Shape: \", size(target))   # prints (rows, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6547fb4",
   "metadata": {},
   "source": [
    "3. Develop a program that allows to encode the categorical values it has in Boolean values, distinguishing the two most common cases (having only two categories and having more than two categories). It should considered the following points: \n",
    "    * The case to be considered between the two possibilities must be automatically detected in the code.  \n",
    "    * The program should start from a vector (one-dimensional array) with the values of a desired attribute or output, and return a vector (one-dimensional array) or matrix (two-dimensional array), depending on the encoding of the desired attribute or output. \n",
    "    * The code must be vectorised, i.e. you cannot use loops to go through the patterns. The only loop that is allowed is for going through classes or attributes, but only this one is allowed. \n",
    "    * This program will be applied to each of the categorical inputs/outputs of the chosen problem.  To do so, keep in mind that in the next tutorial this one will be turn into a function\n",
    "    * _Hint_: it may be interesting to use the function `unique`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c0fbf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Columns: String15[\"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"]\n",
      "Unique labels: String15[\"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "149×3 Matrix{Int64}:\n",
       " 1  0  0\n",
       " 1  0  0\n",
       " 1  0  0\n",
       " 1  0  0\n",
       " 1  0  0\n",
       " 1  0  0\n",
       " 1  0  0\n",
       " 1  0  0\n",
       " 1  0  0\n",
       " 1  0  0\n",
       " ⋮     \n",
       " 0  0  1\n",
       " 0  0  1\n",
       " 0  0  1\n",
       " 0  0  1\n",
       " 0  0  1\n",
       " 0  0  1\n",
       " 0  0  1\n",
       " 0  0  1\n",
       " 0  0  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code to encode the categorical outputs of the problem\n",
    "n_unique_values =  unique(iris.Species)\n",
    "println(\"Unique Columns: \", n_unique_values )   # prints (rows, cols)\n",
    "\n",
    "# Get unique species labels\n",
    "labels = unique(iris.Species)\n",
    "println(\"Unique labels: \", labels )   # prints (rows, cols)\n",
    "# Map each species to an integer\n",
    "label_to_int = Dict(label => i for (i, label) in enumerate(labels))\n",
    "# Encode into integers\n",
    "encoded = [label_to_int[x] for x in iris.Species]\n",
    "#TODO\n",
    "\n",
    "# General One-hot encoding\n",
    "function onehot_encode(y, n_classes)\n",
    "    m = zeros(Int, length(y), n_classes)\n",
    "    # vectorized assignment using CartesianIndex\n",
    "    m[CartesianIndex.(1:length(y), y)] .= 1\n",
    "    return m\n",
    "end\n",
    "onehot = onehot_encode(encoded, length(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "458f45bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels mapping: Dict{String15, Int64}(\"Iris-virginica\" => 3, \"Iris-setosa\" => 1, \"Iris-versicolor\" => 2)\n",
      "One-hot matrix (first 5 rows):\n",
      "[1 0 0; 1 0 0; 1 0 0; 1 0 0; 1 0 0]\n",
      "Target shape: (149, 3)\n",
      "Target First 5 rows:\n",
      "[1 0 0; 1 0 0; 1 0 0; 1 0 0; 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Convert string labels to integers\n",
    "labels = unique(iris.Species)  # ['setosa', 'versicolor', 'virginica']\n",
    "label_to_int = Dict(label => i for (i, label) in enumerate(labels))\n",
    "y_int = [label_to_int[x] for x in iris.Species]  # <-- use iris.Species\n",
    "\n",
    "# Step 2: Get number of labels and samples\n",
    "n_labels = maximum(y_int)\n",
    "n_samples = length(y_int)\n",
    "\n",
    "# Step 3: One-hot encoding\n",
    "if n_labels == 2\n",
    "    # Binary: single column (0/1)\n",
    "    onehot = reshape(y_int .- 1, n_samples, 1)\n",
    "else\n",
    "    # Multi-class: one-hot matrix\n",
    "    onehot = zeros(Int, n_samples, n_labels)\n",
    "    onehot[CartesianIndex.(1:n_samples, y_int)] .= 1\n",
    "end\n",
    "\n",
    "# Step 4: Check result\n",
    "println(\"Labels mapping: \", label_to_int)\n",
    "println(\"One-hot matrix (first 5 rows):\")\n",
    "println(onehot[1:5, :])\n",
    "\n",
    "# Step 5: Set as new target\n",
    "target = onehot\n",
    "\n",
    "# Step 6: Check\n",
    "println(\"Target shape: \", size(target))\n",
    "println(\"Target First 5 rows:\")\n",
    "println(target[1:5, :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a60c84",
   "metadata": {},
   "source": [
    "4. Develop the code that, from the input data set, extracts the maximum, minimum, mean and standard deviation values for each column.  To do this, consult the functions `minimum`, `maximum`, `mean` and `std`. The latter two require the Statistics package to be loaded (`using Statistics`). In addition, these functions accept the additional keyword `dims`.  When it is used properly, `dims` returns a one-row matrix (not a vector) with as many columns as attributes, containing these values of minimum, maximum, mean and standard deviation. Once these one-row matrices have been extracted, use one of the two ways explained here to normalise the database entries.  This task can be done very easily by doing simple broadcast subtraction and division operations, wit not need of loops, as shown in Julia's tutorial. In addition, it will be necessary to consider the following cases: \n",
    "\n",
    "   * If it is normalised between maximum and minimum and in some attribute the minimum is equal to the maximum.\n",
    "   * If it is normalised by mean and standard deviation and in some attribute the standard deviation is 0. <br/>\n",
    "   \n",
    "   Either case, results in the same situation: all patterns take the same value for an attribute. In this case, a common solution is to eliminate the attribute, since it does not provide any information. Another, simpler, possibility is to assign it a constant value, e.g. a value of 0. \n",
    "   One function that can be useful for converting a two-dimensional matrix with a single row or column into a vector is the function vec. Which allows the elements of the matrix to be easily referenced.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba3d85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column-wise means: [5.8483221476510066 3.051006711409396 3.7744966442953025 1.2053691275167786]\n",
      "Column-wise stds: [0.8285940572656173 0.4334988777167476 1.7596511617753423 0.7612920413899604]\n",
      "Column-wise col_mins: [4.3 2.0 1.0 0.1]\n",
      "Column-wise col_maxs: [7.9 4.4 6.9 2.5]\n"
     ]
    }
   ],
   "source": [
    "using Statistics\n",
    "using DataFrames\n",
    "\n",
    "#TODO\n",
    "# 1. Select numeric columns only\n",
    "numeric_cols = names(iris, Number)\n",
    "train_numeric = select(iris, numeric_cols)\n",
    "\n",
    "# 2. Convert to matrix\n",
    "X = Matrix(train_numeric)\n",
    "\n",
    "# 3. Column-wise statistics\n",
    "col_means = mean(X; dims=1)\n",
    "col_stds  = std(X; dims=1)\n",
    "col_mins  = minimum(X; dims=1)\n",
    "col_maxs  = maximum(X; dims=1)\n",
    "\n",
    "println(\"Column-wise means: \", col_means)\n",
    "println(\"Column-wise stds: \", col_stds)\n",
    "println(\"Column-wise col_mins: \", col_mins)\n",
    "println(\"Column-wise col_maxs: \", col_maxs)\n",
    "\n",
    "# 4. Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9e8049c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns only: [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]\n"
     ]
    }
   ],
   "source": [
    "println(\"Numeric columns only: \", numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f2e3b8",
   "metadata": {},
   "source": [
    "As a result of this practice, after applying this function to categorical inputs or outputs, two matrices (desired inputs and outputs) should be available for use in the following practices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acd4605",
   "metadata": {},
   "source": [
    "## Going through this exercises with Julia\n",
    "\n",
    "The first thing to be performed is to load the data, in this case is a excel file and Julian has a package which helps us with this point. Remember that the first time thay are used, they need to be pre-compiled. For example, image a situation where the data is in Excel sheet format, the `readdata` function of the XLSX package can be used to load it. For this, this package must be previously installed, which can be done by typing in the command line the following:\n",
    "```julia\n",
    "    # Only required the first time and when Julia is already setup\n",
    "    import Pkg; Pkg.add(\"XLSX\");\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43987c33",
   "metadata": {},
   "source": [
    "And to use the function in a script, you can write `using XLSX: readdata` at the beginning of the script. \n",
    "To do this exercise, you need to make two calls to load the two arrays. If this data is in an Excel sheet, these calls will look something like this:\n",
    "\n",
    "```julia\n",
    "    using XLSX:readdata\n",
    "\n",
    "    inputs = readdata(\"iris.xlsx\",\"inputs\",\"A1:D150\"); \n",
    "    targets = readdata(\"iris.xlsx\",\"targets\",\"A1:C150\");\n",
    "```\n",
    "\n",
    "In this way, two variables will be loaded into memory, one with the input matrix and the other with the desired output matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ec013b",
   "metadata": {},
   "source": [
    "Alternatively, the data could be in a text file with some kind of delimiter. This is the case, for example, with the `iris.data` file which can be downloaded from [UCI repository - Iris](https://archive.ics.uci.edu/ml/machine-learning-databases/iris/). The DelimitedFiles package is useful for this. This package can be installed in the usual way with:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a445af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg; Pkg.add(\"DelimitedFiles\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab1d5e4",
   "metadata": {},
   "source": [
    "To use it, it can be loaded with keyword `using` at the beginning of the script. One the library is loaded, the dataset can be read into memory like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2888111",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DelimitedFiles \n",
    "\n",
    "dataset = readdlm(\"iris.data\",',');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd608f7",
   "metadata": {},
   "source": [
    "As you can see, the first parameter is the name of the file, while the second is the delimiter or delimiters to be used. In this case, the entire database is loaded into a single variable called a dataset, which will be a two-dimensional array.  In most cases it will be necessary to separate the inputs from the desired outputs. A similar code to the following one would do the job: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213493e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = dataset[:,1:4];\n",
    "targets = dataset[:,5];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52b6645",
   "metadata": {},
   "source": [
    "The bracket operator allows you to reference a particular piece of data or part of an array, the first element referring to rows and the second to columns. When a colon (:) is used, all rows or all columns are referenced, thus returning an array instead of an element.  This will be further explained later in this tutorial. In the particular case of the iris flowers database, the first four columns are the inputs and the fifth one corresponds to the desired output, that is why in these two lines you can see the values 1:4 and 5. In another database, the columns are going to be different.\n",
    "\n",
    "It is important to bear in mind that every variable has a type.  Julia provides a hierarchy of types where the root type is called `Any`. That is, any variable will be of type `Any`.  In this case, reading from a spreadsheet a large amount of data that could be of a different nature (numbers, dates, strings, etc.), it returns a two-dimensional array where each element is of type `Any`. In Julia, this is represented as `Array{Any,2}`, where `Any` indicates the type of each element of the array, and the 2 indicates the number of dimensions.  In the following image the hierarchy of the most common types can be seen (Source: Learning  Julia:  Abstract,  Concrete,  and  Parametric  Types  by  Spencer Russell, Leah Hanson),\n",
    "\n",
    "![Chart with the common types of julia arranged in a tree shape](./img/JuliaTypes.png \"Julia Types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5509d20f",
   "metadata": {},
   "source": [
    "For example, as you can see, `Int64` is a subtype of `Signed`, `Integer`, `Real`, `Number` and `Any`. To see what type a variable is, you can use the function `typeof`. Alternatively, when a particular type is requiredm this can be check with the function `isa`. The types, as well, also have a certain type, which is `DataType`.  The type of `DataType` is `DataType`, which is a subtype of `Any`. Therefore, any element, including types, are of type `Any`, since all types are subtypes of `Any`. For example, try to guest the following types before executing the lines to check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3326e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(Array{Float64,2}) \n",
    "miguel.leal@rai.usc.es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3508e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(DataType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f33467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(Any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d433891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "isa(DataType, Any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83466dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "isa(Any, Any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973623c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "isa(Array{Float32,2}, Any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06237c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "isa(typeof(Array{Float64,2}), Any)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd77dadc",
   "metadata": {},
   "source": [
    "The most common types used in Machine Learning to store numerical data will generally be `Float32` or `Float64`. Although, it is undeniable that `Float32` is the most used in the world of Machine Learning because it is the data type used by most Graphic Processing Units (GPUs), and it is the type we will use in this subject, as it provides sufficient precision for the work to be done. \n",
    "\n",
    "Therefore, it is necessary to convert the data we will use, from `Array{Any,2}` to `Array{Float32,2}`. One possibility is to use the function `convert`, which attempts to do a conversion to a specified type, which could look something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bf8e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = convert(Array{Float32,2},inputs); \n",
    "targets = convert(Array{Float32,1},targets); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cb464f",
   "metadata": {},
   "source": [
    "In this last example, the desired outputs have been converted to a two-dimensional array of real values, which is useful in regression problems with several outputs.  However, in a classification problem such as iris, this line would give an error. The reason is that targets is of type `Array{Any,1}`, where each element is a `String` which cannot be directly converted to `Float32`.  This preprocess has to be always adapted for each particular problem.  For example, if it is a two-class classification problem and the file has numeric values of 0 and 1 for each class, this could be converted to boolean values with something like: \n",
    "\n",
    "```julia\n",
    "        targets = convert(Array{Bool,1}, targets); \n",
    "```\n",
    "\n",
    "If the problem is a classification problem and there are more than two classes, a slightly more complex conversion would have to be performed. This is a matrix, where the number of columns is equal to the number of classes and for each pattern we have a value of true in the column corresponding to the class to which it belongs and false in the rest, as in the exercises of this tutorial. \n",
    "\n",
    "Another option is to force a typecast by using the type itself as a function.  For example, you can specify a number to be of a particular type using something like `Float64(8)`, `Float32(8)`, `Int64(8)`, `UInt32(8)`, etc.  However, you cannot do ~~`Float64(inputs)`~~, because inputs is not of type `Number`, and therefore the conversion is not allowed. Instead of forcing the type of the array, you want a new array to be created where each element is the result of typecasting the corresponding element of the initial array, i.e. a broadcast of the typecasting. \n",
    "\n",
    "One of the key features of Julia is in the handling of multi-dimensional matrices. Julia allows, among other things, to apply functions to all the elements of a matrix and to construct the resulting matrix in an automated way.  In this case, the function is said to be broadcasted over the entire matrix. Let see an example step by step of this procedure. First define the function to be use to broadcast: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9c0f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of a function to calculate the square of an element\n",
    "squared(x::Real) = x*x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a6a1fa",
   "metadata": {},
   "source": [
    "In this case, the type of the argument has been specified as `Real`, which forces the argument to be `Int32`, `Int64`, `Float32`, `Float64`, etc. (if the type of the argument is not specified, by default Julia understands that it is of type Any).  You are therefore defining a function between numbers, not between arrays. For example, the following call would give an error: \n",
    "\n",
    "```julia\n",
    "    squared([1 2 3]) # => Raises MethodError: no method matching squared(::Matrix{Int64})\n",
    "```\n",
    "\n",
    "since this function is defined between numbers and it is passing as argument a matrix, specifically of one row and 3 columns. However, if you wish to construct a new matrix of the same size as the original matrix where each element is the result of applying this function to the corresponding element of the original matrix, this can be done by writing a dot `.` after the name of the function, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e5ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "squared.([1 2 3]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4415271e",
   "metadata": {},
   "source": [
    "Julia is thus indicated to apply this function on an element-by-element level.  These broadcast operations allow you to develop a cleaner code, since you can avoid writing loops, and also more efficient, since Julia can parallel these operations in different cores.  An alternative way to perform this process would be as follows:\n",
    "\n",
    "```julia\n",
    "    [squared(x) for x in [1 2 3]]\n",
    "```\n",
    "\n",
    "Another example but this time with two arguments would be the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca825bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an function to add two numbers\n",
    "add(a::Real, b::Real) = a+b\n",
    "\n",
    "# add([1 2 3],[2 3 4]) => This would give an error because it is not defined for matrices\n",
    "add.([1 2 3],[2 3 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec10b2b",
   "metadata": {},
   "source": [
    "In general, the broacasting of operations can be done in this matrices becasuse they have the same dimension, but could it be use if any of the matrix is smaller or even a single element?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d0e39c",
   "metadata": {},
   "source": [
    "### Questión 1.5\n",
    "> ❓ What would be the result of  add.(1,[2 3 4]) and add.([1 2 3],3)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd3fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcafe32",
   "metadata": {},
   "source": [
    "In general, the most common mathematical operations have the broadcasting implemented.  For example, lets be `A` and `B` two matrices of the same size, to operate element by element, you can do `A.+B`, `A.-B`, `A.*B`or `A./B`. Another example is to do `A.^2`, where a new matrix is constructed where each element is the corresponding element, squared.\n",
    "\n",
    "Returning to the type specification problem with these concepts clear, the following lines would therefore be equivalent:\n",
    "\n",
    "```julia\n",
    "    inputs = Float32.(inputs); \n",
    "    inputs = [Float32(x) for x in inputs]; \n",
    "    inputs = convert(Array{Float32,2},inputs);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdeb8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose the more efficient one and executed here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3c7a76",
   "metadata": {},
   "source": [
    "One key issue that will be important in the definition of functions is a good understanding of Julia's type system. As it was already mentioned, any element, including types, are of type Any, since all types are subtypes of `Any`.  However, one must be careful with types based on others, e.g. arrays, where the elements are of a particular type. In this case, for example, a variable that is of type `Array{Float32,2}` will also be of type `Any`, but not of type `Array{AbstractFloat,2}`, Array{Real,2} nor Array{Number,2} nor Array{Any,2},  because, although Float32 is a subtype of `AbstractFloat`, `Real`, `Number` and `Any`, the type `Array{Float32,2}` is not a subtype of `Array{AbstractFloat,2}`, `Array{Real,2}`, `Array{Number,2}` or `Array{Any,2}`. To indicate whether in a type of this style its elements are subtypes of others, the `<:` operator shall be used as can be seen in the following example. This is quite useful in function definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66988a3",
   "metadata": {},
   "source": [
    "### Question 1.6\n",
    "> ❓ Which would be the answer of the following lines? Think about before executing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0c0aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(inputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ab560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "isa(inputs, Any) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce043b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "isa(inputs, Array) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba47f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "isa(inputs, Array{Float32,2}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d664b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "isa(inputs, Array{Real,2}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2add8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "isa(inputs, Array{Number,2}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b59bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "isa(inputs, Array{Any,2}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788f22a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "isa(inputs, Array{<:Real,2}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38055279",
   "metadata": {},
   "outputs": [],
   "source": [
    "isa(inputs, Array{<:Number,2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3166834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "isa(inputs, Array{<:Any,2}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df89ebac",
   "metadata": {},
   "source": [
    "Additionaly, the `<:` operator can also be used to check whether one type is a subtype of another, as can be seen in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e21bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Array{Float32,2} <: Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc13395",
   "metadata": {},
   "outputs": [],
   "source": [
    "Array{Float32,2} <: Array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b1cf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Array{Float32,2} <: Array{Any,2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29940d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "Array{Float32,2} <: Array{<:Real,2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "Array{Float32,2} <: Array{<:Any,2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f64dcf",
   "metadata": {},
   "source": [
    "As noted above, this conversion of the targets is useful for regression problems. However, if the problem is a binary classification problem, and we are given these targets  as numeric values, 0 or 1, the following lines would be equivalent: \n",
    "```julia\n",
    "    targets = Bool.(targets); \n",
    "    targets = [Bool(x) for x in targets]; \n",
    "    targets = convert(Array{Bool,1},targets);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2981e529",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chose one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08fa87d",
   "metadata": {},
   "source": [
    "With respect to vectors and matrices of Boolean values, there are two types that in most cases can be used interchangeably, which are `Array{Bool,N}` and `BitArray{N}`, where N indicates the dimensionality of the array.  The `Array{Bool,N}` type stores each Boolean value as a value of type `Bool`, which is represented internally as a value of type `UInt8`. Therefore, if the array has n elements, it will need n bytes to store it. On the other hand, the `BitArray{N}` type stores each Boolean value as a bit, so n elements need n/8 bytes to be stored, a much smaller amount than the `Array{Bool,N}` type. Depending on the situation, it may be more efficient to store in one way or the other. In any case, the most common operations are defined for both types, so in the vast majority of cases they are interchangeable and therefore one or the other can be used. When defining functions, it is important to bear in mind that both are subtypes of `AbstractArray{Bool,N}`, as can be seen in the following examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f691ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "BitArray{2} <: AbstractArray{Bool,2} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea68815",
   "metadata": {},
   "outputs": [],
   "source": [
    "Array{Bool,2} <: AbstractArray{Bool,2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea01820",
   "metadata": {},
   "source": [
    "In this way, we will have a matrix with the inputs of type `Array{Float32,2}`.  The matrix with the  targets will need to be constructed depending on the nature of the problem to be solved.   Although `Array{Float32,2}` is the type that will be used the most in this course, bear in mind that data types in Julia are very flexible. For example, you could have a variable containing a three-dimensional array where each element is a vector, the type would be  \n",
    "`Array{Array{Float32,1},3}`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a861db7",
   "metadata": {},
   "source": [
    "### Question 1.7\n",
    "> ❓ What type will the objects [[[]], [[8]] and [[8.]] have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befb355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f15166",
   "metadata": {},
   "source": [
    "Generally speaking, in Machine Learning, in the matrices each instance is in a row. Whereas, in the columns of the input matrix the attributes are represented, in the target matrix each of the outputs is represented.  Therefore, both matrices must have the same number of rows.\n",
    "\n",
    "In order to calculate the number of rows and/or columns of a matrix, the function `size` can be used. This function returns a tuple, with the number of elements equal to the number of dimensions, where each element indicates the size of that dimension.  For example, the call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e2ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "size(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc6639f",
   "metadata": {},
   "source": [
    "For the Iris problem it should return (150, 4), i.e. 150 rows and 4 columns. It is also possible to call this function indicating from which dimension you want to read the size. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff077d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "size(inputs,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc09ed5",
   "metadata": {},
   "source": [
    "This instruction should return a 150 value. In this case, if the loading of the database has been done correctly, both matrices should have the same number of rows. However, such issues should often be checked in order to find possible errors.  For that, in many parts of the code it is often interesting to introduce checks to verify that everything is correct.  When this check is executed, if it is not true, the system should give an error. This is called defensive programming. In the case of Julia, this can be done with the macro `@assert`, to which the check to be performed is indicated, and, optionally, the error message that should appear, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728942d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert (size(inputs,1)==size(targets,1)) \"The number of rows in inputs and targets do not match\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da207ad",
   "metadata": {},
   "source": [
    "As the variable targets is a vector, i.e. a one-dimensional array, the previous call to `size(targets,1)` could be replaced by `length(targets)`.\n",
    "\n",
    "At this point, and once the exercises of this practice have been carried out, two matrices should be loaded in memory, both with the same number of rows.  **Important:** Unlike in the rest of the models, in the world of Artificial Neural Networks, it is usually understood that each instance is represented in a column of the input matrix, with the rows being the attributes, and the rows of the target matrix being the outputs of the ANN.\n",
    "\n",
    "Therefore, the first tutorial together with the introduction to Julia would conclude at this point. You should remembre t complete the exercises at the begining of this tutorial. Additionaly, it would be recommended to copy that same piece of code to a `.jl` file.\n",
    "\n",
    "In the remaining of this tutorial, the spotlight is going to be on the use of matrices together with the broadcast of functions which is one of Julia's strong points, as it was aforementioned. It is particularly efficient and it is done in a very similar way to Matlab. So, we are going along with this objetive, we are going to show some common operations.\n",
    "\n",
    "To create a vector, its elements can be enclosed in square brackets, separated by commas, for example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63658f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4f6d33",
   "metadata": {},
   "source": [
    "To create a matrix, simply enclose its elements in square brackets, separating the rows by semicolons `;`, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2dfc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = [1 2 3; 4 5 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e575d17e",
   "metadata": {},
   "source": [
    "To access an element of the matrix, enter the name of the matrix followed by the row and column to be accessed in square brackets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fc047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "M[2,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2191d73",
   "metadata": {},
   "source": [
    "In this particular case, `M` is a bidimensional matrix, so two values have been indicated in square brackets.  If it has a different dimensionality, it would be necessary to indicate a value for each dimension.  For example, if it was 3-dimensional, it would be necessary to write `M[2,3,1]`. \n",
    "\n",
    "### Question 1.8\n",
    "> ❓ What will be the result of the following calls? When representing a vector as a matrix, will it be a row matrix or a column matrix? Does the third call return a vector or a two-dimensional matrix? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a33a267",
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc86538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof([1;2;3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a56be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof([1 2 3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a68ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof([1 2 3; 4 5 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7684dedb",
   "metadata": {},
   "source": [
    "The sequence operator `:` is used in many languages as a built-in range operator, which is used to create vectors. For example, in Matlab, `J:K` is equivalent to creating the vector `[J, J+1, ..., K]` whenever `J < K`.  Also, `J:D:K` is equivalent to [J,J+D, J+2* D,..., K]. For example, the following operations are equivalent in Matlab: \n",
    "\n",
    "```matlab\n",
    "    1:3\n",
    "    [1 2 3]\n",
    "```\n",
    "However, in Julia there is a slight difference, although the operability remains the same. The difference is that J:D:K does not create a vector but an element of type `UnitRange` or `StepRange`, which stores the initial and final indices and the increment, and which can be used in the same way as a vector.  Generally speaking, this eliminates the need to create vectors when they are absolutely necessary, for example in loops.  Moreover, this is done transparently to the developer, since, as mentioned above, the operability is the same as in the case of creating explicit vectors. \n",
    "\n",
    "The operator : can also be used to select rows, columns or parts of an array. These operators can be used in conjunction with the word end, which indicates that the range will end at the last value of the row or column. For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b2eed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "M[:, 1]     # retrieve the first column of the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f39718",
   "metadata": {},
   "outputs": [],
   "source": [
    "M[1, 2:end] # retrive the first row only columns from secong to the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b433da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "M[2, :]     # retrive the second row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8163bf1",
   "metadata": {},
   "source": [
    "**Important:** When referencing elements of an array for each dimension where no range is given but a single value, e.g. a row or a column, that dimension will be lost. Beware of the result in the previous examples. \n",
    "\n",
    "As previously mentioned, the operability with this object is the same as with vectors.  For example, these two lines give the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9740e8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "M[1, end:-1:1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b88c4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "M[1, [3, 2, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c493e168",
   "metadata": {},
   "source": [
    "In these two examples, as you can see, one dimension is \"lost\" since only one row, the first one, is being referenced. Therefore, the result will be a vector, that is, an array of dimension 1. Something similar happens when a vector (array of dimension 1) is referenced by making an element.  For example, M[3] in a vector \"loses\" the dimension it had and returns a 0-dimensional object (a scalar value).  If instead of referencing by a scalar, it is referenced by a range or a vector, then it will not \"lose\" that dimension, but possibly decrease it.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514cf4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = [1, 2, 3];\n",
    "M[:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77f899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "M[1:end] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47100826",
   "metadata": {},
   "outputs": [],
   "source": [
    "M[end:-1:1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5a45e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "M[1:3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26641878",
   "metadata": {},
   "outputs": [],
   "source": [
    "M[[1,2,3]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70223b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "M[[1, 2, 3, 1, 2, 3]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d52c405",
   "metadata": {},
   "outputs": [],
   "source": [
    "M[[2]] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20a96b4",
   "metadata": {},
   "source": [
    "In all these cases a vector is returned. However, the last example is interesting to finish understanding how the operator works to reference parts of arrays.  In this example, a single element vector is returned. A vector is returned because a vector has been used for referencing, and it has only one element because this vector used for referencing has only one element.  Therefore, what is returned is a different object than if it had been referenced by M[2], the result of which is a scalar value, namely the second element of the M vector. \n",
    "\n",
    "### Question 1.9\n",
    "> ❓ If M were a 4-dimensional matrix, how many dimensions would the results of the following operations have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62619ae4",
   "metadata": {},
   "source": [
    "Q = #TODO Define a 4 dimension matrix\n",
    "length(size(Q[:, :, :, :])) == #COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3ea4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "length(size(Q[1, 2, 3, 4])) == 1 #COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da93e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "length(size(length(size(Q[1, 2, 3, :] )) == #COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eedb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "length(size(Q[:, [1, 2, 3], 4, :] )) == #COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277caa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "length(size(Q[:, [1, 2, 3], :, :] )) == #COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b526005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "length(size(Q[[3, 2], 2, 4, :] )) == #COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a25e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "length(size(Q[[3, 2], [2], [4], [1]]  )) == #COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fe3cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "length(size(Q[1, [1, 2, 3], 4, :])) == #COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f74f84",
   "metadata": {},
   "source": [
    "To transpose matrices, you can use the function `transpose`, or use the `'` operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82d7e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "M'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d17590",
   "metadata": {},
   "source": [
    "As a result, the object it returns is not of type `Array`, but a more complicated type that encapsulates an `Array`.  Julia does this so as not to have to reserve memory for the new transposed array, but simply reference its elements in another order, taking advantage of the memory that is already allocated.  This object, despite not being of type `Array`, is a subtype of `AbstractArray`, so it can be used indistinctly as if it were an Array.\n",
    "\n",
    "As indicated above, Julia allows you to braadcasting a function to all the elements of a matrix and also to perform operations between the elements of matrices located in the same position. For the latter, operators such as multiplication, division or power are prefixed with a dot `.`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ce79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = [10 20 30; 40 50 60]; \n",
    "\n",
    "N*M "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ba4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "N.*M "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400ed56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N./M "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db1eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N/10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ace683",
   "metadata": {},
   "outputs": [],
   "source": [
    "N>30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd2ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "N.>30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bf04ef",
   "metadata": {},
   "source": [
    "In this last example, a matrix of Boolean values is created in which each element is the result of comparing each element of the matrix with the value 30.\n",
    "\n",
    "### Question 1.10\n",
    "> ❓ Why does it give an error when trying to execute N*M but not N.*M? Why does it give an error when trying to execute N>30 but not N.>30? Correct the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645bc590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ca48d5f",
   "metadata": {},
   "source": [
    "Unlike Matlab or Python, Julia does not allow matrices to grow dynamically.  For example, in Matlab in the matrix above, it is possible to give a value to an element located in a position that does not exist.  In this case, it will not give an error, opositely,  Matlab would have increased the size of the matrix up to that position, filling the new values with zeros. In Julia, however, this will cause an error, since the matrices have defined sizes similar to R.\n",
    "\n",
    "An additional functionality of broadcasting operations between arrays is that they need not be only between arrays of the same size or arrays and scalar values, but can be done between arrays of the same dimensionality but with different sizes.  This is widely used in the operation with two-dimensional arrays, and in this subject it will be used to normalise the data. If an operation is broadcasted between a (two-dimensional) matrix and another two-dimensional matrix with a single column, both with the same number of rows, this operation will be performed as if the second matrix had the same size as the first one, with the column repeated.  The same is true if the second matrix is a one-row matrix with the same number of columns.  Of course, it makes no difference which one comes first in the operation.  Several simple examples are shown below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e7b4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = [1 2; 3 4; 5 6; 7 8];\n",
    "\n",
    "M.+[1 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138e6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "M.+[4; 3; 2; 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dfea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "[4; 3; 2; 1].+M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139c4197",
   "metadata": {},
   "outputs": [],
   "source": [
    "M.+[4, 3, 2, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e55e61",
   "metadata": {},
   "source": [
    "Notice the last example, if the row matrix or column matrix is a vector, it will be treated as a column matrix.\n",
    "\n",
    "To declare an array and thus reserve the relevant memory, you can use the type of that array as if it were a function. To do this, the first argument is the way to initialise the data, and then a number for each dimension.  The most common way to initialise the data is to use `undef`, which indicates that you do not want to initialise the values of the array. The array will, therefore, have whatever values are in memory at the time.  For example, the following call creates a two-dimensional array of 10 rows and 6 columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a901e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Array{Float32,2}(undef, 10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae97729",
   "metadata": {},
   "source": [
    "### Question 1.11\n",
    "> ❓ Why will the following expression gives an error? Correct it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fdc392",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Array{Float32,2}(undef, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1a26b0",
   "metadata": {},
   "source": [
    "### Question 1.12\n",
    "> ❓ What will be the result of the following calls?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf20668",
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(Array{Float32,2}(undef, 4, 15)) == #COMPLETE (name the type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd2bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(Array{Float32,2}) == #COMPLETE (name the type) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea471b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "isa(Array{Float32,2}, Array{Float32,2}) == # COMPLETE (true or false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152dadb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "isa(Array{Float32,2}(undef, 4, 10), Array{Float32,2}) == # COMPLETE (true or false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc33771",
   "metadata": {},
   "source": [
    "Another possibility is to use the functions `zeros` or `ones`, which create arrays of the given size where all elements are 0 or 1 respectively, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854f6f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros(10, 6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fa771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c1b387",
   "metadata": {},
   "source": [
    "To concatenate two vectors, you can put them in square brackets, separating the elements by `;`.  For example, the following line allows you to create a vector resulting from concatenating the vectors indicated: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6f3aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[1, 2, 3]; [4, 5, 6]] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6917a9",
   "metadata": {},
   "source": [
    "To merge matrices, this is done in a similar way, using square brackets. To put them \"next to\" each other, they are separated by a space. This can be done as long as the number of rows of the matrices match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91fbbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[1 2 3; 4 5 6] [7 8 9; 10 11 12]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88022e2f",
   "metadata": {},
   "source": [
    "In case you want to put one \"under\" the other, the separation must be done with the operator `;` .  As opposed to the previous case, in this one the number of columns must match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c21fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[1 2 3; 4 5 6] ; [7 8 9; 10 11 12]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c7cd60",
   "metadata": {},
   "source": [
    "If `[[1, 2, 3]; [4, 5, 6]]`\n",
    "allows concatenating vectors, what will be the result of the following operations? What will be the type of the result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e4e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[1, 2, 3]  [4, 5, 6]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b878cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[1, 2, 3], [4, 5, 6]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238e556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[1  2  3]  [4  5  6]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09605214",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[1  2  3]; [4  5  6]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4447bebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[1  2  3], [4  5  6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd37051b",
   "metadata": {},
   "source": [
    "Julia has a number of functions for working with matrices such as ones, zeros, size, length, max, min, minmax, rand, inv, det, sum, etc. Some of the most commonly used are: \n",
    "\n",
    "- `zeros`: takes as parameters the size of each dimension, and creates an array of that dimensionality and size, where all elements are equal to 0. \n",
    "\n",
    "- `ones`: takes as parameters the size of each dimension, and creates an array of that dimensionality and size, where all elements are equal to 1. \n",
    "\n",
    "- `rand`: takes as parameters the size of each dimension, and creates an array of that dimensionality and size, where all elements are random values. \n",
    "\n",
    "- `size`: receives as parameter an array and returns a tuple with as many elements as the dimensionality of the array, where each element is the size of that array.  It can be called with the dimension as a second argument, and returns only the size of that dimension. \n",
    "\n",
    "- `maximum`: receives an array as a parameter and returns the maximum value of the array. Optionally, It also accepts a dim keyword that specifies the dimension to apply the function to. \n",
    "\n",
    "- `minimum`: performs the operation similar to maximum, but returns the minimum value instead of the maximum. It also accepts the dims keyword.\n",
    "\n",
    "- `findall`: takes an array of boolean values as a parameter and returns the indices of the positive values. \n",
    "\n",
    "- `sum`: receives as parameter an array and the sum of the values of the array. It also accepts the dims keyword. \n",
    "\n",
    "- `mean`: takes an array as parameter and returns the average value of the array.  It also accepts the keyword dims.  Requieres a preload of  `Statistics` package. \n",
    "\n",
    "- `std`: takes an array as a parameter and returns the standard deviation of the values in the array.  It accepts also the keyword dims. Requieres a preload of  `Statistics` package. \n",
    "\n",
    "As it was pointed out, many of these functions accept the `dims` keyword to indicate along which dimension the specified operation will be performed.  If not used, this operation is performed on all elements of the array.  However, if `dims=1` is specified, this function is performed in parallel on each column, and as a result a matrix of one row and as many columns as the original matrix had will be returned. The returned value of each column will be the result of applying the function on the elements of vector formed by the column of the original matrix. \n",
    "Opositely, if `dims=2` is specified, this operation is performed in parallel on each row, and the sresults is a matrix of one column and as many rows as the original matrix. The value of each row will be the result of applying the function on the vector of elements of that row of the original matrix.For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a49bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([1 2; 3 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37400634",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([1 2; 3 4], dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e356fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([1 2; 3 4], dims=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b7bcb1",
   "metadata": {},
   "source": [
    "In general, to see the documentation of a function, simply need to type `?`. If do so, the prompt would change from the normal `julia>` to `help?>`. Now, by simply typing the name of the function the system will retrive the documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbebf0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.6",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
